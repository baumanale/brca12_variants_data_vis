{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input for specific gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene_name = input('Gene name: ')\n",
    "# files\n",
    "fasta_in = r'data_folders/FASTA_files_UCSC/' + gene_name.lower() + '_fasta'\n",
    "syn_out = r'data_folders/Syn_table_out/' + gene_name.lower() + '_syn.csv'\n",
    "# reference transcript\n",
    "dfrefseqtr = pd.read_table(r'data_folders/biomart_refseq.txt')\n",
    "refseqtr = list(dfrefseqtr['RefSeq accession'].loc[dfrefseqtr['Approved symbol'] == gene_name.upper()])[0]\n",
    "# reference sequence\n",
    "refsq = r'data_folders/ref_seq/' + gene_name.lower() + '_full_seq_ref'\n",
    "list_refsq = r'data_folders/ref_seq/' + gene_name.lower() + '_seq_ref.csv'\n",
    "# flossies\n",
    "floss_in = r'data_folders/Flossies_annotations/flossies_' + gene_name.lower() + '.csv'\n",
    "floss_out = r'data_folders/Flossies_annotations/flossies_' + gene_name.lower() + '_out.csv'\n",
    "#cBioPortal\n",
    "cbp_in = r'data_folders/cbioportal_annotations/cbioportal_' + gene_name.lower() + '.tsv'\n",
    "cbp_out = r'data_folders/cbioportal_annotations/cbioportal_' + gene_name.lower() + '_out.csv'\n",
    "# gnomAD\n",
    "gAD_in = r'data_folders/gnomAD_annotations/gnomAD_' + gene_name.lower() + '.csv'\n",
    "gAD_out = r'data_folders/gnomAD_annotations/gnomAD_' + gene_name.lower() + '_out.csv'\n",
    "# VEP\n",
    "vep_path_in = r'data_folders/VEP_data/' + gene_name.lower() + r'/' + gene_name.lower() + '_in'\n",
    "vep_path_out = r'data_folders/VEP_data/' + gene_name.lower() + r'/' + gene_name.lower() + '_out'\n",
    "vep_for_in = r'data_folders/VEP_data/' + gene_name.lower() + r'/' + gene_name.lower() + r'_in/vep_id_' + gene_name.lower() + '.txt'\n",
    "vep_data = vep_path_out + r'/'  + gene_name.lower() + r'_vep_data.txt'\n",
    "vep_out = r'data_folders/VEP_data/' + gene_name.lower() + r'/' + gene_name.lower() + '_out.csv'\n",
    "# joint file\n",
    "joint_out = r'joint_files_out/' + gene_name.lower() + '_joint_out.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(list_refsq,'w') as oref:\n",
    "    # result in dictionary format\n",
    "    resultD_ref={}\n",
    "    # write first line in new document 'o'\n",
    "    oref.write('CHROM,POS,REF,Ref_Genome,Strand,Ref_Transcript,Trans_Version_Syn\\n')\n",
    "    # FASTA sequence by UCSC Genome Browser\n",
    "    with open(refsq) as fref:\n",
    "        for record in SeqIO.parse(fref, 'fasta'):\n",
    "            # take first number from position range as variable 's', with iteration through sequence s+=1 = position\n",
    "            s=int(record.description.split('range')[1].split(':')[1].split('-')[0])\n",
    "            # take reference genome\n",
    "            refg = record.description.split('_')[0]\n",
    "            # take chromosome number\n",
    "            chrom=record.description.split('range')[1].split('chr')[1].split(':')[0]\n",
    "            # take strand +/-\n",
    "            strand=record.description.split('strand')[1][1]\n",
    "            # take transcript, split by '_', but then NM and number separated\n",
    "            trans=record.description.split('RefSeq_')[1].split('.')[0]\n",
    "            # for transcript version\n",
    "            trans_vers = record.description.split('.')[1].split(' ')[0]\n",
    "            # for '-' strands: reverse complement and reverse exon order + 1\n",
    "            if strand == '-':\n",
    "                record.seq = record.seq.reverse_complement()\n",
    "            else:\n",
    "                pass                \n",
    "            # only for reference transcript\n",
    "            if trans == refseqtr:\n",
    "                # iterate through sequence by nucleotide\n",
    "                for nuc in str(record.seq):\n",
    "                    # all nucleotides in upper case\n",
    "                    nuc = str(nuc.upper())\n",
    "                    # entr = specific position of each nucleotide (for key in dictionary)\n",
    "                    entr = (refg + '_' + chrom + '_' +str(s) + '_' + strand + '_' + nuc + '_' + str(trans_vers))\n",
    "                    # if nucleotide with specific position is not yet in resulting dictionary\n",
    "                    if entr not in resultD_ref:\n",
    "                        # append specific transcript as value of the specific position (= key) in dictionary\n",
    "                        resultD_ref[entr]=trans\n",
    "                    else:\n",
    "                        resultD_ref[entr]=resultD_ref[entr]#+' '+trans\n",
    "                    s+=1\n",
    "                \n",
    "    # address dictionary with both features (key and value), sort the dictionary\n",
    "    i = 0\n",
    "    for key,value in sorted(resultD_ref.items()):\n",
    "        # every key element (specific position element) is connected by '_' --> split by '_' to access each key\n",
    "        x=key.split('_')\n",
    "        # write in new document 'oref'\n",
    "        oref.write(str(x[1])+ ',' + str(x[2])+ ',' + str(x[4])+ ',' + str(x[0])+ ',' + str(x[3])+ ',' + value +\n",
    "                   ',' + str(x[5])+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new document, referred to as 'o'\n",
    "# either every transcript or only reference transcript\n",
    "with open(syn_out,'w') as o:\n",
    "    # result in dictionary format\n",
    "    resultDict={}\n",
    "    # write first line in new document 'o'\n",
    "    o.write('Identifier,CHROM,POS,REF,ALT,Ref_Genome,Strand,Ref_Transcript,Trans_Version_Syn\\n')\n",
    "    # open document with FASTA sequence, referred to as 'f'\n",
    "    # FASTA sequence by UCSC Genome Browser\n",
    "    with open(fasta_in) as f:\n",
    "        # parse: all single features as a list iterator\n",
    "        for record in SeqIO.parse(f, 'fasta'):\n",
    "            # .split()[].split(): split by (), then take the piese [] and split it by ()\n",
    "            # take first number from position range as variable 's', with iteration through sequence s+=1 = POS\n",
    "            s=int(record.description.split('range')[1].split(':')[1].split('-')[0])\n",
    "            # take reference genome\n",
    "            refg = record.description.split('_')[0]\n",
    "            # take chromosome number\n",
    "            chrom=record.description.split('range')[1].split('chr')[1].split(':')[0]\n",
    "            # take strand +/-\n",
    "            strand=record.description.split('strand')[1][1]\n",
    "            # take transcript, split by '_', but then NM and number separated\n",
    "            trans=record.description.split('RefSeq_')[1].split('.')[0]\n",
    "            # for transcript version\n",
    "            trans_vers = record.description.split('.')[1].split('_')[0]\n",
    "            # for '-' strands: reverse complement and reverse exon order + 1\n",
    "            if strand == '-':\n",
    "                record.seq = record.seq.reverse_complement()\n",
    "            else:\n",
    "                pass                \n",
    "            # only for reference transcript\n",
    "            if trans == refseqtr:\n",
    "                # iterate through sequence by nucleotide\n",
    "                for nuc in str(record.seq):\n",
    "                    # all nucleotides in upper case\n",
    "                    nuc = str(nuc.upper())\n",
    "                    # for specific nucleotide, print list of alternative nucleotides\n",
    "                    alt = 'ACGT'.replace(str(nuc), '')\n",
    "                    # for nuc in alternative nucleotides entry for dictionary\n",
    "                    for cr in alt:\n",
    "                        # entr = specific position of each nucleotide (for key in dictionary)\n",
    "                        entr = (refg + '_' + chrom + '_' +str(s) + '_' + strand + '_' + nuc + '_' + cr\n",
    "                             + '_' + str(trans_vers))\n",
    "                    # if nucleotide with specific position is not yet in resulting dictionary\n",
    "                        if entr not in resultDict:\n",
    "                        # append specific transcript as value of the specific position (= key) in dictionary\n",
    "                            resultDict[entr]=trans\n",
    "                        else:\n",
    "                        # if specific nucleotide position is already in dictionary, append other transcript(s)\n",
    "                            resultDict[entr]=resultDict[entr]#+' '+trans\n",
    "                    s+=1\n",
    "                \n",
    "    # address dictionary with both features (key and value), sort the dictionary\n",
    "    i = 0\n",
    "    for key,value in sorted(resultDict.items()):\n",
    "        # every key element (specific position element) is connected by '_' --> split by '_' to access each key\n",
    "        x=key.split('_')\n",
    "        # for identifier to integrate information to specific position later on\n",
    "        identi = str(x[1]) + ':g.' + str(x[2]) + str(x[4]) + '>' + str(x[5])\n",
    "        # write in new document 'o'\n",
    "        o.write(str(identi)+ ',' +str(x[1])+ ',' +str(x[2])+ ',' +str(x[4])+ ',' +str(x[5])+ ',' +str(x[0])+\n",
    "                ',' + str(x[3])+ ',' + value + ',' + str(x[6]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating FLOSSIES annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(floss_in)\n",
    "df_ref = pd.read_csv(list_refsq)\n",
    "\n",
    "dff.rename(columns = {'Annotation':'Consequence_Flossies', 'Splice Change':'Splice_Change_Flossies', \n",
    "                      'European (n=7325)':'European_(n=7325)_Flossies', 'African (n=2559)':'African_(n=2559)_Flossies', \n",
    "                      'Overall Frequency':'Overall_Frequency_Flossies', 'Chrom':'CHROM', 'Position':'POS', 'Reference':'REF', 'Alternate':'ALT'}, inplace = True)\n",
    "\n",
    "# for deletion\n",
    "# position = position - 1\n",
    "dff['POS'].loc[dff['ALT'].isna()] = dff['POS'].astype(int) - 1\n",
    "df_del = dff.loc[dff['ALT'].isna()].copy()\n",
    "\n",
    "d = 0\n",
    "new_ref_del_l = []\n",
    "new_alt_del_l = []\n",
    "for d in range(len(df_del)):\n",
    "    # position of nucleotide of first element of dataframe in which 'Alternate' not filled out\n",
    "    pos_flossies = df_del.iloc[d]['POS']\n",
    "    # reference nucleotide at specific position\n",
    "    ref_refseq = list(df_ref['REF'].loc[df_ref['POS'].astype(int) == pos_flossies])[0]\n",
    "    # for alternative nucleotide reference nucleotide\n",
    "    new_alt_del_l.append(ref_refseq)\n",
    "    # reference nucleotide of first element of dataframe in which 'Alternate' not filled out\n",
    "    ref_flossies = df_del.iloc[d]['REF']\n",
    "    # new reference nucleotides for vcf annotation\n",
    "    new_ref_del = ref_refseq + ref_flossies\n",
    "    new_ref_del_l.append(new_ref_del)\n",
    "# add new columns\n",
    "df_del['REF_n'] = new_ref_del_l\n",
    "df_del['ALT_n'] = new_alt_del_l\n",
    "df_del.drop(columns = ['REF', 'ALT'], inplace = True)\n",
    "df_del.rename(columns = {'REF_n':'REF', 'ALT_n':'ALT'}, inplace = True)\n",
    "#df_del\n",
    "\n",
    "# for insertion\n",
    "# position = position, because something was inserted at this position\n",
    "df_ins = dff.loc[dff['REF'].isna()].copy()\n",
    "\n",
    "i = 0\n",
    "new_alt_ins_l = []\n",
    "new_ref_ins_l = []\n",
    "for i in range(len(df_ins)):\n",
    "    # position of nucleotide of first element of dataframe in which 'Reference' missing\n",
    "    pos_flossies = df_ins.iloc[i]['POS']\n",
    "    # reference nucleotide at specific position\n",
    "    ref_refseq = list(df_ref['REF'].loc[df_ref['POS'].astype(int) == pos_flossies])[0]\n",
    "    # for reference nucleotide reference nucleotide\n",
    "    new_ref_ins_l.append(ref_refseq)\n",
    "    # reference nucleotide of first element of dataframe in which 'Reference' missing\n",
    "    alt_flossies = df_ins.iloc[i]['ALT']\n",
    "    # new alternate nucleotides for vcf annotation\n",
    "    new_alt_ins = ref_refseq + alt_flossies\n",
    "    new_alt_ins_l.append(new_alt_ins)\n",
    "# add new columns\n",
    "df_ins['ALT_n'] = new_alt_ins_l\n",
    "df_ins['REF_n'] = new_ref_ins_l\n",
    "df_ins.drop(columns = ['REF', 'ALT'], inplace = True)\n",
    "df_ins.rename(columns = {'REF_n':'REF', 'ALT_n':'ALT'}, inplace = True)\n",
    "#df_ins\n",
    "\n",
    "df_snv = dff.loc[dff['ALT'].notna()].loc[dff['REF'].notna()]\n",
    "\n",
    "df_floss = df_snv.append([df_del, df_ins])\n",
    "df_floss = df_floss.sort_index()\n",
    "\n",
    "# create column for identifier and transcript version\n",
    "df_floss['Trans_Version_Flossies']= 3\n",
    "df_floss['Identifier'] = df_floss['CHROM'].astype(str) + ':g.' + df_floss['POS'].astype(str) + df_floss['REF'] + '>' + df_floss['ALT']\n",
    "\n",
    "# select only wanted columns\n",
    "df_floss_n = df_floss[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'Trans_Version_Flossies', 'Consequence_Flossies', 'Splice_Change_Flossies', \n",
    "                        'European_(n=7325)_Flossies', 'African_(n=2559)_Flossies', 'Overall_Frequency_Flossies']].sort_values(by='Identifier')\n",
    "df_floss_n\n",
    "# creating Identifier list for VEP\n",
    "#df_floss_n['Identifier'].to_csv('floss_id_for_vep.txt', index = False)\n",
    "#df_floss_n1 = pd.read_csv('floss_id_for_vep.txt', skiprows = 1)\n",
    "#df_floss_n1.to_csv('0415floss_vep.txt', index = False)\n",
    "df_floss_n.to_csv(floss_out, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating cBioPortal annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = pd.read_table(cbp_in)\n",
    "df_ref = pd.read_csv(list_refsq)\n",
    "\n",
    "BP.rename(columns = {'Chromosome':'CHROM', 'Start Pos':'POS', 'Cancer Type':'Cancer_Type_cBP', 'Protein Change':'Protein_Change_cBP', \n",
    "                     'Ref':'REF', 'Var':'ALT', 'Annotation':'Annotation_cBP', 'Functional Impact':'Functional_Impact_cBP', 'MS':'MS_cBP'}, inplace = True)\n",
    "\n",
    "# some withouut CHROM number --> drop\n",
    "BP['CHROM'] = BP['CHROM'].fillna(0)\n",
    "BP = BP.loc[(BP['CHROM'] != 0)]\n",
    "BP['MS_cBP'] = BP['MS_cBP'].replace('.', np.nan)\n",
    "BP['CHROM'] = BP['CHROM'].astype(int)\n",
    "\n",
    "# for deletion\n",
    "# position = position - 1\n",
    "BP['POS'].loc[BP['ALT'] == '-'] = BP['POS'].astype(int) - 1\n",
    "df_del = BP.loc[BP['ALT'] == '-'].copy()\n",
    "\n",
    "d = 0\n",
    "new_ref_del_l = []\n",
    "new_alt_del_l = []\n",
    "for d in range(len(df_del)):\n",
    "    # position of nucleotide of first element of dataframe in which 'Alternate' not filled out\n",
    "    pos_cbp = df_del.iloc[d]['POS']\n",
    "    # reference nucleotide at specific position\n",
    "    ref_refseq = list(df_ref['REF'].loc[df_ref['POS'].astype(int) == pos_cbp])[0]\n",
    "    # for alternative nucleotide reference nucleotide\n",
    "    new_alt_del_l.append(ref_refseq)\n",
    "    # reference nucleotide of first element of dataframe in which 'Alternate' not filled out\n",
    "    ref_cbp = df_del.iloc[d]['REF']\n",
    "    # new reference nucleotides for vcf annotation\n",
    "    new_ref_del = ref_refseq + ref_cbp\n",
    "    new_ref_del_l.append(new_ref_del)\n",
    "# add new columns\n",
    "df_del['REF_n'] = new_ref_del_l\n",
    "df_del['ALT_n'] = new_alt_del_l\n",
    "df_del.drop(columns = ['REF', 'ALT'], inplace = True)\n",
    "df_del.rename(columns = {'REF_n':'REF', 'ALT_n':'ALT'}, inplace = True)\n",
    "#df_del\n",
    "\n",
    "# for insertion\n",
    "# position = position, because something was inserted at this position\n",
    "df_ins = BP.loc[BP['REF'] == '-'].copy()\n",
    "\n",
    "i = 0\n",
    "new_alt_ins_l = []\n",
    "new_ref_ins_l = []\n",
    "for i in range(len(df_ins)):\n",
    "    # position of nucleotide of first element of dataframe in which 'Reference' missing\n",
    "    pos_cbp = df_ins.iloc[i]['POS']\n",
    "    # reference nucleotide at specific position\n",
    "    ref_refseq = list(df_ref['REF'].loc[df_ref['POS'].astype(int) == pos_cbp])[0]\n",
    "    # for reference nucleotide reference nucleotide\n",
    "    new_ref_ins_l.append(ref_refseq)\n",
    "    # reference nucleotide of first element of dataframe in which 'Reference' missing\n",
    "    alt_cbp = df_ins.iloc[i]['ALT']\n",
    "    # new alternate nucleotides for vcf annotation\n",
    "    new_alt_ins = ref_refseq + alt_cbp\n",
    "    new_alt_ins_l.append(new_alt_ins)\n",
    "# add new columns\n",
    "df_ins['ALT_n'] = new_alt_ins_l\n",
    "df_ins['REF_n'] = new_ref_ins_l\n",
    "df_ins.drop(columns = ['REF', 'ALT'], inplace = True)\n",
    "df_ins.rename(columns = {'REF_n':'REF', 'ALT_n':'ALT'}, inplace = True)\n",
    "#df_ins\n",
    "\n",
    "df_snv = BP.loc[BP['ALT'] != '-'].loc[BP['REF'] != '-']\n",
    "\n",
    "df_BP = df_snv.append([df_del, df_ins])\n",
    "df_BP = df_BP.sort_index()\n",
    "\n",
    "df_BP['Identifier'] = df_BP['CHROM'].astype(str) + ':g.' + df_BP['POS'].astype(str) + df_BP['REF'] + '>' + df_BP['ALT']\n",
    "\n",
    "df_BP[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'Cancer_Type_cBP', 'Protein_Change_cBP', 'Annotation_cBP', 'Functional_Impact_cBP', 'MS_cBP']].to_csv(cbp_out, index = False)\n",
    "#df_BP[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'Cancer_Type_cBP', 'Protein_Change_cBP', 'Annotation_cBP', 'Functional_Impact_cBP', 'MS_cBP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating gnomAD annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD = pd.read_csv(gAD_in)\n",
    "\n",
    "# rename some columns\n",
    "AD.rename(columns = {'Chromosome':'CHROM', 'Position':'POS', 'Reference':'REF', 'Alternate':'ALT', 'ClinVar Clinical Significance':'ClinVar_gnomAD', \n",
    "                     'Allele Count':'AC_gnomAD', 'Allele Number':'AN_gnomAD', 'Allele Frequency':'AF_gnomAD', \n",
    "                     'Homozygote Count':'HOM_gnomAD', 'Hemizygote Count':'HEMI_gnomAD'}, inplace = True)\n",
    "\n",
    "# create column for identifier\n",
    "AD['Identifier'] = AD['CHROM'].astype(str) + ':g.' + AD['POS'].astype(str) + AD['REF'].astype(str) + '>' + AD['ALT'].astype(str)\n",
    "\n",
    "AD[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'ClinVar_gnomAD', 'AC_gnomAD', 'AN_gnomAD', 'AF_gnomAD', 'HOM_gnomAD']].to_csv(gAD_out, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating variants of NCT MASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gene_name.lower().startswith('brca'):\n",
    "    NM = pd.read_excel(r'data_folders/NCT_MASTER_variants/NCT_MASTER_BRCA_Variants_hg191.xlsx')\n",
    "    NM.rename(columns = {'#CHROM':'CHROM', 'NCT PID':'NCT_PID', 'NCT SAMPLE_NAME':'NCT_SAMPLE_NAME', 'NCT Sheet':'NCT_Sheet', 'KGE RefSeq (MSKCC)':'KGE_RefSeq', 'NCT TumorVariantFrequency(TVF)':'NCT_TumorVariantFrequency', 'NCT ZYGOSITY':'NCT_ZYGOSITY'}, inplace = True)\n",
    "\n",
    "    NM['CHROM'] = NM['CHROM'].astype(int)\n",
    "    # for BRCA1: CHROM == 17, for BRCA2: CHROM = 13\n",
    "    chromos = 0\n",
    "    if gene_name.lower() == 'brca1':\n",
    "        chromos = 17\n",
    "    elif gene_name.lower() == 'brca2':\n",
    "        chromos = 13\n",
    "\n",
    "    NM_br = NM.loc[NM['CHROM'] == chromos]\n",
    "\n",
    "    # for insertion\n",
    "    # position = position, because something was inserted at this position\n",
    "    df_ins = NM_br.loc[NM_br['REF'].isnull()].copy()\n",
    "\n",
    "    i = 0\n",
    "    new_alt_ins_l = []\n",
    "    new_ref_ins_l = []\n",
    "    for i in range(len(df_ins)):\n",
    "        # position of nucleotide of first element of dataframe in which 'Reference' missing\n",
    "        pos_nct = df_ins.iloc[i]['POS']\n",
    "        # reference nucleotide at specific position\n",
    "        ref_refseq = list(df_ref['REF'].loc[df_ref['POS'].astype(int) == pos_nct])[0]\n",
    "        # for reference nucleotide reference nucleotide\n",
    "        new_ref_ins_l.append(ref_refseq)\n",
    "        # reference nucleotide of first element of dataframe in which 'Reference' missing\n",
    "        alt_nct = df_ins.iloc[i]['ALT']\n",
    "        # new alternate nucleotides for vcf annotation\n",
    "        new_alt_ins = ref_refseq + alt_nct\n",
    "        new_alt_ins_l.append(new_alt_ins)\n",
    "    # add new columns\n",
    "    df_ins['ALT_n'] = new_alt_ins_l\n",
    "    df_ins['REF_n'] = new_ref_ins_l\n",
    "    df_ins.drop(columns = ['REF', 'ALT'], inplace = True)\n",
    "    df_ins.rename(columns = {'REF_n':'REF', 'ALT_n':'ALT'}, inplace = True)\n",
    "    #df_ins\n",
    "\n",
    "    df_others = NM_br.loc[NM_br['REF'].notnull()]\n",
    "\n",
    "    df_NM_br = df_others.append(df_ins)\n",
    "    df_NM_br = df_NM_br.sort_index()\n",
    "\n",
    "    df_NM_br['Identifier'] = df_NM_br['CHROM'].astype(str) + ':g.' + df_NM_br['POS'].astype(str) + df_NM_br['REF'].astype(str) + '>' + df_NM_br['ALT'].astype(str)\n",
    "\n",
    "    df_NM_br[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'NCT_SAMPLE_NAME', 'NCT_Sheet', 'KGE_RefSeq', 'NCT_TumorVariantFrequency', 'NCT_ZYGOSITY']].to_csv((r'data_folders/NCT_MASTER_variants/0504_nct_master_' + gene_name.lower() + '.csv'), index = False)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Findlay data (BRCA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gene_name.lower() == 'brca1':\n",
    "    findl = pd.read_excel(r'data_folders/findlay/findlay_data.xlsx', skiprows = 2)\n",
    "    findl['Identifier'] = findl['chromosome'].astype(str) + ':g.' + findl['position (hg19)'].astype(str) + findl['reference'].astype(str) + '>' + findl['alt'].astype(str)\n",
    "    findl['Trans_Version_Findlay']= 3\n",
    "    findl.rename(columns = {'consequence':'Consequence_Findlay', 'func.class':'Function_Findlay', 'chromosome':'CHROM', 'position (hg19)':'POS', 'reference':'REF', 'alt':'ALT'}, inplace = True)\n",
    "    findl[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'Trans_Version_Findlay', 'Consequence_Findlay', 'Function_Findlay']].to_csv(r'data_folders/findlay/findlay_data_out.csv', index = False)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Richardson et al data (BRCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gene_name.lower() == 'brca2':\n",
    "    rich = pd.read_excel(r'data_folders/richardson_data/rich_et_al_brca2.xlsx', skiprows = [0, 1, 255, 256, 257, 258, 259, 260, 261, 261, 263])\n",
    "    rich.drop([252], inplace = True)\n",
    "    rich.rename(columns = {'Unnamed: 1':'as_var_short'}, inplace = True)\n",
    "    # lists for protein position and protein exchange\n",
    "    npos = []\n",
    "    prot = []\n",
    "    for x in range(len(rich)):\n",
    "        pos = re.findall('\\d+', rich.iloc[x]['as_var_short'])\n",
    "        pro = rich.iloc[x]['as_var_short'].split('.')[1]\n",
    "        npro = re.sub('\\d+', '/', pro)\n",
    "        prot.append(npro)\n",
    "        npos.append(pos)\n",
    "    new_pos = []\n",
    "    for el in npos:\n",
    "        newp = ','.join(el)\n",
    "        new_pos.append(newp)\n",
    "    rich['Protein_position'] = new_pos\n",
    "    rich['Amino_acids'] = prot\n",
    "    rich['CHROM'] = 13\n",
    "    rich.rename(columns = {'Variant':'Variant_Rich', 'HDR Score':'HDR_Rich', '95% CI lower bound':'95%_CI_lower_bound_Rich', '95%CI upper bound':'95%_CI_upper_bound_Rich', 'Previously Published HDR Study1-3':'Prev_HDR_Rich'}, inplace = True)\n",
    "    rich[['CHROM', 'Protein_position', 'Amino_acids', 'Variant_Rich', 'HDR_Rich', '95%_CI_lower_bound_Rich', '95%_CI_upper_bound_Rich', 'Prev_HDR_Rich']].to_csv(r'data_folders/richardson_data/0517_richardson.csv', index = False)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating VEP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# producing VEP data\n",
    "vep_syn = pd.read_csv(syn_out)\n",
    "vep_floss = pd.read_csv(floss_out)\n",
    "vep_cbp = pd.read_csv(cbp_out)\n",
    "vep_ga = pd.read_csv(gAD_out)\n",
    "vep_nct = pd.read_csv((r'data_folders/NCT_MASTER_variants/0504_nct_master_' + gene_name.lower() + '.csv'))\n",
    "\n",
    "# creating Identifier lists for VEP\n",
    "full_vep = pd.concat([vep_syn[['Identifier', 'CHROM', 'POS', 'REF', 'ALT']], vep_floss[['Identifier', 'CHROM', 'POS', 'REF', 'ALT']], vep_cbp[['Identifier', 'CHROM', 'POS', 'REF', 'ALT']], vep_ga[['Identifier', 'CHROM', 'POS', 'REF', 'ALT']], vep_nct[['Identifier', 'CHROM', 'POS', 'REF', 'ALT']]])\n",
    "full_vep.drop_duplicates(inplace = True, ignore_index = True)\n",
    "\n",
    "# deletion problem VEP\n",
    "full_vep_wo_del = full_vep.loc[full_vep['REF'].str.len() == 1].copy()\n",
    "full_vep_wo_del['VEP_ID'] = full_vep_wo_del['CHROM'].astype(str) + ':g.' + full_vep_wo_del['POS'].astype(str) + full_vep_wo_del['REF'].astype(str) + '>' + full_vep_wo_del['ALT'].astype(str)\n",
    "\n",
    "full_vep_del =  full_vep.loc[full_vep['REF'].str.len() > 1]\n",
    "\n",
    "vep_REF = []\n",
    "for d in range(len(full_vep_del)):\n",
    "    vep_REF.append(full_vep_del.iloc[d]['REF'][1:])\n",
    "full_vep_del['vep_REF'] = vep_REF\n",
    "\n",
    "full_vep_del['VEP_ID'] = full_vep_del['CHROM'].astype(str) + ':g.' + (full_vep_del['POS'].astype(int) + 1).astype(str) + 'del' + full_vep_del['vep_REF'].astype(str)\n",
    "\n",
    "all_vep = full_vep_wo_del.append(full_vep_del)\n",
    "all_vep.sort_index()\n",
    "\n",
    "all_vep['VEP_ID'].to_csv(vep_for_in, index = False, header = False)\n",
    "\n",
    "# with vep_for_in --> go to http://grch37.ensembl.org/Homo_sapiens/Tools/VEP?db=core\n",
    "# save as 'gene_name.lower()_vep_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP = pd.read_table(vep_data)\n",
    "VEP.rename(columns = {'#Uploaded_variation':'VEP_ID', 'Consequence':'Consequence_VEP', 'IMPACT':'Impact_VEP', \n",
    "                     'Existing_variation':'Existing_variation_VEP', 'CADD_PHRED':'CADD_PHRED_VEP', 'CADD_RAW':'CADD_RAW_VEP', 'SIFT':'SIFT_VEP', 'PolyPhen':'PolyPhen_VEP', \n",
    "                     'ada_score':'Ada_score_VEP'}, inplace = True)\n",
    "\n",
    "# only use rows with reference transcripts\n",
    "VEP = VEP.replace('-', np.nan)\n",
    "\n",
    "new = VEP['Feature'].str.split('.')\n",
    "transcr = []\n",
    "for el in new:\n",
    "    transcr.append(el[0])\n",
    "VEP['Ref_Trans_VEP'] = transcr\n",
    "\n",
    "\n",
    "df_VEP = VEP.loc[VEP['Ref_Trans_VEP'] == refseqtr]\n",
    "df_VEP.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#pd.merge(all_vep['']\n",
    "\n",
    "df_VEP[['VEP_ID', 'Ref_Trans_VEP', 'Consequence_VEP', 'Impact_VEP']]\n",
    "\n",
    "new_VEP = pd.merge(df_VEP, all_vep, on = ['VEP_ID'])\n",
    "\n",
    "# only a few columns in file\n",
    "new_VEP[['Identifier', 'CHROM', 'POS', 'REF', 'ALT', 'Ref_Trans_VEP', 'Consequence_VEP', 'Impact_VEP', 'EXON', 'INTRON', 'Protein_position', \n",
    "         'Amino_acids', 'Codons', 'SIFT_VEP', 'PolyPhen_VEP', 'CADD_PHRED_VEP', 'CADD_RAW_VEP', 'Ada_score_VEP']].to_csv(vep_out, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read .csv as dataframe\n",
    "fsyn = pd.read_csv(syn_out)\n",
    "ffloss = pd.read_csv(floss_out)\n",
    "fcbp = pd.read_csv(cbp_out)\n",
    "fga = pd.read_csv(gAD_out)\n",
    "fvep = pd.read_csv(vep_out)\n",
    "if gene_name.lower().startswith('brca'):\n",
    "    fnct = pd.read_csv((r'data_folders/NCT_MASTER_variants/0504_nct_master_' + gene_name.lower() + '.csv'))\n",
    "else:\n",
    "    pass\n",
    "if gene_name.lower() == 'brca1':\n",
    "    ffindlay = pd.read_csv(r'data_folders/findlay/findlay_data_out.csv')\n",
    "else:\n",
    "    pass\n",
    "if gene_name.lower() == 'brca2':\n",
    "    frich = pd.read_csv(r'data_folders/richardson_data/0517_richardson.csv')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join/merge all dfs\n",
    "# if position is in synthetic list with 75 bp padding\n",
    "m = fvep.loc[fvep['POS'].isin(list(fsyn['POS']))]\n",
    "\n",
    "m1 = m.merge(fsyn, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "m2 = m1.merge(ffloss, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "m3 = m2.merge(fcbp, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "m4 = m3.merge(fga, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "if gene_name.lower().startswith('brca'):\n",
    "    m5 = m4.merge(fnct, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "    if gene_name.lower() == 'brca1':\n",
    "        jnt = m5.merge(ffindlay, on = ['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], how = 'left')\n",
    "    elif gene_name.lower() == 'brca2':\n",
    "        jnt = m5.merge(frich, on = ['CHROM', 'Protein_position', 'Amino_acids'], how = 'left')\n",
    "else:\n",
    "    m4 = jnt\n",
    "jnt.drop_duplicates(['Identifier', 'CHROM', 'POS', 'REF', 'ALT'], inplace = True, ignore_index = True)\n",
    "\n",
    "#new document with all annotations at specific positions\n",
    "jnt.to_csv(joint_out, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
